\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}

\usepackage{geometry}
\geometry{a4paper}
\usepackage{graphicx}
\usepackage{float}
\usepackage[italian]{babel}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per il disegno di curve 2D
\usepackage{pgfplots}
\pgfplotsset{compat=newest}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per l'uso del multiriga nelle tabelle
\usepackage{multirow}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per produrre pagine landscape in un documento principalmente portrait
\usepackage{pdflscape}

\usepackage{adjustbox}

\usepackage{subcaption}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%comando per la gestione semplificata di quotes
\newcommand{\quotes}[1]{``#1''}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%librerie per la visualizzazione del codice
\usepackage{listings}
\lstset{
	language=bash,
	basicstyle=\ttfamily,
	frame=tblr,
}

\usepackage{pythonhighlight}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%libreria per l'inserimento di link nella
%   bibliografia
\PassOptionsToPackage{hyphens}{url}\usepackage[hidelinks]{hyperref}

\linespread{1.2}
\setlength{\parindent}{0pt}

\begin{document}

%----------------------------------------------------------------------------------------
%	TITOLO
%----------------------------------------------------------------------------------------

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\center

\textsc{\Large Relazione di progetto di \quotes{Smart City e Tecnologie Mobili}}\\[0.5cm]

\HRule \\[0.4cm]
{
	\huge \bfseries
	Rilevatore di sonnolenza\\
	all'interno di un autoveicolo con\\
	Raspberry Pi\\[0.4cm]
}
\HRule \\[1.5cm]

\vfill

\begin{flushleft}
\emph{Numero del gruppo:}\\
62\\[1cm]
\emph{Componenti del gruppo:}\\
Giacomo Frisoni\\
Marcin Pabich\\[3cm]
\end{flushleft}



\end{titlepage}

%----------------------------------------------------------------------------------------
%	INDICE
%----------------------------------------------------------------------------------------

\tableofcontents

\newpage

%----------------------------------------------------------------------------------------
%	INTRODUZIONE
%----------------------------------------------------------------------------------------

\section{Introduzione}

Il deterioramento delle capacità alla guida causato da sonnolenza è noto per essere uno dei fattori che contribuiscono maggiormente alla formazione di incidenti automobilistici. Secondo un sondaggio del 2011 realizzato dalla National Sleep Foundation sulla popolazione americana, circa il 30\% degli incidenti su strada è dovuto all'affaticamento del conducente e tale dato tende a crescere di anno in anno\cite{SleepInAmerica}. Una recente indagine svolta dalla NHTSA\footnote{NHTSA. National Highway Traffic Safety Administration.} ha inoltre stimato un numero complessivo di 90.000 incidenti in America segnalati dalla polizia nel 2015 (con 41.000 feriti e più di 800 morti), aventi come causa l'insorgere di uno stato di sonnolenza\cite{NHTSA}.\\
La sonnolenza costituisce nello specifico una fase di transizione nel ciclo sonno-veglia, determinante uno stato di torpore e una riduzione del livello di coscienza della persona. Nell'ambito in esame, la sonnolenza deteriora le prestazioni del guidatore e può infine portare all'incapacità di resistere al sonno al volante. Essa può essere dovuta a diversi fattori: condizioni di guida avverse, traffico intenso, alti carichi di lavoro, scarso riposo, orari notturni, disturbi del sonno, abuso di alcol e assunzione di medicinali sono solo alcuni esempi. Tutti questi fattori hanno effetti cumulativi e una loro combinazione può aumentare in modo sostanziale il rischio di incidenti stradali. Gli aspetti critici su cui impatta la sonnolenza alla guida, invece, sono i tempi di reazione, la vigilanza, il livello di attenzione e la velocità nell'elaborare le informazioni.\\
A partire dal 1995 i ricercatori hanno iniziato a concentrare i propri sforzi sulla costruzione di dispositivi di allarme, come una tra le principali tecniche di contromisura. L'obiettivo di questi sistemi è quello di allarmare o risvegliare i conducenti che sono assonnatti o addormentati, riducendo conseguentemente la percentuale di scontri e avvenimenti inattesi sul suolo stradale. Una carenza intrinseca in tutti i tipi di dispositivi di allarme, tuttavia, è da ricercarsi nel fatto che molte persone continuano a guidare anche quando sanno di essere sonnolenti, lottando per rimanere svegli. Sebbene un dispositivo di allarme efficace possa prevenire un incidente, un autista che si addormenta una volta rischia di addormentarsi nuovamente a meno che non smetta di guidare. Da diversi anni gli esperti di sicurezza hanno espresso preoccupazione sul fatto che i dispositivi di allarme possano fornire ai conducenti un falso senso di sicurezza, incoraggiandoli a guidare per lungo tempo\cite{DrowsyDrivingReport}.\\
Il progetto descritto in questo documento si pone l'obiettivo di realizzare un sistema a basso costo, affidabile e non intrusivo per il riconoscimento della stanchezza del conducente in tempo reale, svolgendo un monitoraggio video sul suo volto e applicando tecniche di Computer Vision sui frame catturati. L'implementazione della soluzione si basa sull'uso di un \textit{Raspberry Pi 3 B}, un single-board computer noto per le sue caratteristiche prestazionali rapportate al prezzo e alle dimensioni che lo contraddistinguono.\\
Il sistema acquisisce le immagini dell'utente per mezzo di una camera installata nell'automobile e posizionata frontalmente a esso. La sonnolenza del guidatore è successivamente calcolata in riferimento a una misura comportamentale incentrata sulla chiusura degli occhi (stimata quantitativamente con metodologia \textit{EAR}\footnote{EAR. Eye Aspect Ratio.}\cite{EAR}). A fronte di una chiusura degli occhi protrattasi oltre un tempo definito, il sistema riproduce un allarme per mezzo di un buzzer acustico al fine di reclamare l'attenzione dell'utente ed evidenziare il potenziale pericolo che sta incorrendo.\\
Le principali tecnologie adottate sono \textit{Python} a livello di linguaggio di programmazione, \textit{OpenCV}\cite{OpenCV} come libreria per la manipolazione di foto e video, \textit{dlib}\cite{Dlib} per quanto concerne gli algoritmi di machine learning per l'individuazione e la localizzazione di facial landmark.\\
Il contributo tecnologico/scientifico apportato dal gruppo con l'elaborato in esame si riferisce allo studio e al confronto prestazionale delle varie soluzioni che possono essere implementate, specie in relazione ai limiti dell'hardware adottato. Una particolare attenzione è riposta nelle tecniche di riconoscimento facciale: esse rappresentano la base dell'intero processo e sono note per essere l'elemento centrale sia per la determinazione dell'efficacia del sistema nei vari scenari d'uso che per la sua reale efficienza.

\iffalse
Esporre l’obiettivo del progetto dandone una visione complessiva.\\
Devono essere illustrate le caratteristiche salienti del progetto; deve essere chiara la distinzione tra le tecnologie usate/assemblate durante lo svolgimento dell’elaborato e il contributo tecnologico/scientifico effettivamente apportato dal gruppo.\\

Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
	& Numero minimo di battute & Numero massimo di battute \\
	\hline
	1 componente & 2000 & 3000 \\
	2 componenti & 2500 & 4500 \\
	3 componenti & 3000 & 6000 \\
	\hline
\end{tabular}
\fi

\newpage


%----------------------------------------------------------------------------------------
%	STATO DELL'ARTE
%----------------------------------------------------------------------------------------

\section{Stato dell'arte}

Misurare direttamente il livello di sonnolenza è complesso. Esistono tuttavia numerosi metodi indiretti capaci di rilevare aspetti correlati e che oggi costituiscono la base per i vari sistemi disponibili sul mercato.
In questa sezione si riportano le soluzioni presenti in letteratura per quanto concerne il problema in esame, distinguendole sulla base del tipo di misura su cui si basano (riassunte in Figura \ref{fig:StateOfTheArt}). Inoltre si citano quelle già operative sul mercato: lo sviluppo di tecnologie per il rilevamento di sonnolenza, infatti, costituisce una sfida sia accademica che industriale.

\subsection{Misure fisiologiche}

Le misure di segnali fisiologici comprendono tecniche quali ECG (elettrocardiogramma), EOG (elettrooculogramma), EEG (elettroencefalogramma) e HRV\footnote{HRV. Heart Rate Variability.}.
Il segnale EEG, in particolare, è il più utilizzato nella classe fisiologica per la misurazione della stanchezza. Esso fornisce informazioni sull'attività del cervello e consente pertanto di individuare la perdita di concentrazione e il rallentamento dei tempi di risposta tipici di chi è affetto da affaticamento e sonnolenza. Il segnale EEG ha varie bande di frequenza: \textit{delta} (0,5-4 Hz) - corrispondente al sonno, \textit{theta} (4-8 Hz) - legata alla stanchezza, \textit{alpha} (8-13 Hz) - rappresentante uno stato di rilassamento e creatività, \textit{beta} (13-25 Hz) - corrispondente a uno stato di vigilanza. Una diminuzione della variazione di potenza nella banda di frequenza \textit{alpha} e un relativo aumento in \textit{theta} è pertanto indice di sonnolenza. Secondo uno studio condotto nel 2011\cite{EEG}, le tecniche EEG sono le più accurate, con un tasso di precisione superiore al 90\%. Tuttavia, le misure fisiologiche faticano a essere adottate nella realtà a causa dei loro costi, della connessione fisica che richiedono con l'autista e dello stress indotto tipicamente nell'utente che indossa le apparecchiature di monitoraggio necessarie. Una soluzione più pratica è stata studiata per Jaguar Land Rover\cite{Jaguar}.

\subsection{Misure basate sul veicolo}

La maggior parte delle soluzioni attualmente disponibili e impiegate dalle case automobilistiche riguardano misure basate sul veicolo e comprendono pertanto l'individuazione di scostamenti rispetto alla propria corsia, la pressione esercitata sui pedali e il movimento delle ruote sterzanti. Si tratta dunque di approcci basati su modelli di guida che hanno lo svantaggio di dipendere fortemente dalle caratteristiche del veicolo, dalle condizioni della strada e dalle capacità del conducente.\\
In un paper del 2009\cite{SWM} un gruppo di ricercatori ha rilevato il livello di sonnolenza con un'accuratezza dell'86\%, considerando le correlazioni tra le micro-regolazioni esercitate sul volante per il mantenimento dell'automobile (individuate grazie a sensori per la misurazione dell'angolo di sterzata) in corsia e l'affaticamento del guidatore stesso. Tale tecnica di rilevamento è denominata SWM\footnote{SWM. Steering Wheel Movement.}.\\
Un'altra misura basata sul veicolo spesso utilizzata per misurare la sonnolenza del conducente è SDLP\footnote{SLDP. Standard Deviation of Lane Position.}, dove la posizione della corsia viene tracciata per mezzo di una telecamera esterna. Il principale limite di questa tecnica risiede nella dipendenza da fattori quali la segnaletica orizzontale, l'illuminazione e le condizioni climatiche.\\
I sistemi implementati oggi all'interno delle automobili di fascia alta tengono in genere conto di un insieme di parametri. Il Driver Alert di Ford\cite{Ford}, il Safety-IBuzz Fatigue Alert di Skoda\cite{Skoda} e il Bosch Driver Drowsiness Detection System\cite{Bosch} adottato da Volkswagen sono i più conosciuti esempi industriali.

\subsection{Misure comportamentali}

Le soluzioni basate su misure di tipo comportamentale sono le più diffuse negli ultimi anni. Esse si basano sulle caratteristiche tipiche del movimento facciale nelle persone assonnate: rapidi e costanti battiti di ciglia, chiusura degli occhi, annuenza o oscillazione della testa e frequenti sbadigli. La maggior parte degli studi pubblicati sugli approcci comportamentali per la determinazione della sonnolenza si focalizza sul battito di ciglia. Sotto questo punto di vista, la misura del PERCLOS\footnote{PERCLOS. Percentuale di chiusura della palpebra sopra la pupilla nel tempo. Riflette la tipica chiusura rallentata degli occhi nei soggetti affetti da sonnolenza.} costituisce la tecnica più diffusa e impiegata anche nell'ambito dei prodotti commerciali.\\
Il principale limite legato all'uso di tecniche di Computer Vision per l'estrazione di feature facciali è l'illuminazione. Le camere normali non consentono di ottenere risultati soddisfacenti in scenari notturni. Per ovviare il problema, alcuni ricercatori hanno fatto uso di una illuminazione infrarossi tramite LED\footnote{LED. Light Emitting Node.}\cite{IEEE} (che consente buone prestazioni di notte ma è meno robusta durante il giorno). Le immagini vengono acquisite dalla camera a un certo frame rate, elaborate per garantire prima l'estrazione del volto e poi per localizzare la specifica regione d'interesse (ad esempio tramite Haar Cascade Classifier o HOG) su cui realizzare il calcolo della misura scelta. Approcci più recenti, infine, si basano su Deep Learning.

\begin{figure}
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{eps/eeg.eps}
		\caption{Esempio pratico di misura fisiologica con casco EEG.}
	\end{subfigure}
	\hspace{5mm}
	\begin{subfigure}{.55\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{eps/swm.eps}
		\caption{Funzionamento della misura SWM\\basata sul veicolo.}
	\end{subfigure}
	\par\bigskip % force a bit of vertical whitespace
	\begin{subfigure}{.55\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{eps/sdlp.eps}
		\caption{Funzionamento della misura SLDP basata\\sul veicolo.}
	\end{subfigure}
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{eps/ear.eps}
		\caption{Misure comportamentale incentrate sulla chiusura degli occhi calcolata con tecniche di Computer Vision.}
	\end{subfigure}
	\caption{Esempi di soluzioni per il rilevamento della sonnolenza alla guida, con distinzione nella misura adottata.}
	\label{fig:StateOfTheArt}
\end{figure}

\subsection{Confronto col progetto presentato}
Il progetto analizzato in questa relazione realizza il rilevamento della sonnolenza attraverso una misura comportamentale incentrata sulla chiusura degli occhi del conducente. Si basa pertanto su tecniche di Computer Vision sia per la \textit{face detection} che per l'estrazione dei \textit{facial landmark}. L'apertura degli occhi è calcolata mediante l'EAR, una soluzione diffusa in letteratura (come alternativa al PERCLOS) e nota per i suoi vantaggi: stima incentrata su una sola grandezza scalare, superamento dei risultati allo stato dell'arte su due dataset standard, e ricavabile attraverso una semplice formula da una sola immagine. L'adozione del Raspberry Pi 3 B come piattaforma hardware di riferimento vincola in misura maggiore rispetto alle soluzioni presentate l'applicabilità di algoritmi di visione, costringendo a considerare con massimo riguardo il trade-off tra accuratezza e velocità d'elaborazione (real-time per requisito).

\iffalse
Riassumere le soluzioni presenti in letteratura inerenti al problema in esame. Per ciascuna, discutere le principali diversità o affinità rispetto al progetto presentato. Nel caso non siano presenti soluzioni direttamente comparabili a quella presentata descrivere comunque le principali tecniche note per affrontare la tematica trattata.\\

Le soluzioni esposte devono essere corredate degli opportuni riferimenti bibliografici. Nel caso si tratti di soluzioni già operative sul mercato, devono essere indicate le fonti (online) dove poter accedere al servizio o approfondirne i contenuti.\\

Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 2000 & 3000 \\
 2 componenti & 2500 & 4500 \\
 3 componenti & 3000 & 6000 \\
 \hline
\end{tabular}
\fi

\newpage


%----------------------------------------------------------------------------------------
%	ANALISI DEI REQUISITI
%----------------------------------------------------------------------------------------

\section{Analisi dei requisiti}
\label{sec:requisiti}

In questa sezione sono trattati in modo dettagliato tutti i requisiti del progetto, emersi durante la fase di analisi.

\subsection{Business Requirements}
\begin{enumerate}
	\item Realizzare un progetto di qualità sia nella sua parte software che hardware, valutandone accuratamente le prestazioni.
	\item Organizzare il lavoro in team, definendo un apposito piano e sperimentando la suddivisione di task mediante diagramma di Gantt.
	\item Mettere alla prova le conoscenze acquisite durante il corso relative ai sistemi embedded, al Raspberry Pi, alla videosorveglianza e alle tecnologie di sensing.
\end{enumerate}

\subsection{User Requirements}
\begin{enumerate}
	\item Possibilità di posizionare il dispositivo all'interno del veicolo, frontalmente al conducente.
	\item Capacità del sistema di riconoscere il livello di sonnolenza del guidatore, considerando una misura comportamentale basata sulla chiusura degli occhi.
	\begin{enumerate}
		\item Il sistema deve considerare il guidatore in uno stato di sonnolenza e pertanto in una situazione di pericolo se la chiusura dei suoi occhi si protrae per un tempo eccessivo.
		\item Nella misurazione della sonnolenza, il sistema deve tener conto della reale apertura di ambo gli occhi.
	\end{enumerate}
	\item Avvio automatico del sistema all'atto dell'alimentazione.
	\item Attivazione o disattivazione del rilevamento su richiesta del conducente.
	\begin{enumerate}
		\item Il sistema deve procedere al monitoraggio del volto del conducente, al rilevamento del suo grado di sonnolenza e alla segnalazione di scenari di pericolo solo se attivo.
	\end{enumerate}
	\item Gestione degli scenari d'uso legati al riconoscimento del volto.
	\begin{enumerate}
		\item Volto rilevato. Il sistema deve procedere con la misura dell'indice di sonnolenza.
		\item Volto non rilevato. Il sistema non deve produrre allarmi, evitando segnalazioni potenzialmente non connesse a situazioni di reale pericolosità.
	\end{enumerate}
	\item Segnalazione acustica e visiva degli scenari di pericolo rilevati.
\end{enumerate}

\subsection{Functional Requirements}
\begin{enumerate}
	\item Il sistema deve monitorare il viso dell'utente attraverso una camera.
	\item La misurazione della sonnolenza del conducente deve avvenire grazie a tecniche di Computer Vision.
	\begin{enumerate}
		\item Il sistema deve applicare tecniche di face recognition per l'individuazione del volto.
		\item Il sistema deve applicare tecniche di facial landmarking per l'individuazione delle sole coordinate di interesse per quanto concerne gli occhi.
		\item Il sistema deve rilevare la chiusura degli occhi nei vari frame grazie al calcolo dell'EAR per ognuno di essi.
		\item Si considera la presenza di uno scenario di pericolo nel momento in cui la misura dell'EAR indica la chiusura degli occhi per un definito numero di frame consecutivi, ritenuto di adatta sensibilità per gli obiettivi del sistema.
	\end{enumerate}
	\item Il sistema deve avviare il software di rilevamento nella fase di reboot.
	\item Il sistema deve consentire l'avvio o l'arresto della rilevazione mediante la pressione di un pulsante.
	\begin{enumerate}
		\item L'acquisizione dei frame dalla camera e la loro successiva elaborazione devono avvenire solo se il sistema è attivo.
	\end{enumerate}
	\item Il sistema deve adottare un comportamento idoneo sia a fronte del riconoscimento del volto che del fallimento di tale fase.
	\begin{enumerate}
		\item Volto rilevato. Il sistema deve procedere con l'estrazione dei facial landmark e il calcolo dell'EAR per entrambi gli occhi.
		\item Volto non rilevato. Il sistema deve procedere con l'analisi dei successivi frame, senza segnalare situazioni di pericolo.
	\end{enumerate}
	\item Il sistema deve segnalare al conducente la presenza di uno scenario di pericolo causato dal rilevamento di sonnolenza, adottando due tipologie distinte di avvertimento.
	\begin{enumerate}
		\item Avvertimento acustico, per mezzo di un buzzer sonoro.
		\item Avvertimento visivo, per mezzo di LED.
	\end{enumerate}
\end{enumerate}

\subsection{Non-functional Requirements}
\begin{enumerate}
	\item \textbf{Dimensioni.} Il sistema deve avere dimensioni conformi per una sua installazione a bordo di un autoveicolo, in modo da non ostacolare in alcun modo la guida. L'intera soluzione deve pertanto essere facile da trasportare e poco ingombrante.
	\item \textbf{Real-time.} Il sistema deve essere in grado di elaborare i frame catturati e di fornire segnalazioni di pericolo in tempo reale, specie in considerazione della velocità con cui il veicolo potrebbe essere in movimento. Ciò ha impatto sia sulla scelta dell'hardware - che deve risultare di sufficiente capacità computazionale - sia sulla progettazione del software - che non deve rivelarsi eccessivamente complesso nel rispetto delle limitate risorse che si hanno a disposizione sulla piattaforma scelta.
	\item \textbf{Affidabilità.} Il rilevamento della sonnolenza del conducente deve avvenire nel modo più accurato possibile, riducendo al minimo il numero di falsi positivi e consentendo solo ridotti margini di errore. Il sistema deve essere robusto a eventuali variazioni dell'ambiente, della luminosità e dell'orientamento del volto. Ove possibile, inoltre, l'oggettistica, gli indumenti indossati e la colorazione della pelle del guidatore non devono compromettere il funzionamento del sistema stesso.
\end{enumerate}

\subsection{Implementation Requirements}
\begin{enumerate}
	\item \textbf{Raspberry Pi 3 B}. La componente hardware del sistema deve essere basata su Raspberry Pi 3 B, un single-board computer economico, di ridotte dimensioni e di buone capacità computazionali. La ragione alla base di tale scelta è da ricercarsi nella volontà di approfondire le conoscenze apprese durante il corso di Smart City e Tecnologie Mobili, acquisendo anche esperienza nello sviluppo di progetti basati su questo tipo di piattaforma.
	\item \textbf{Budget}. La realizzazione del sistema deve avvenire a basso costo da un punto di vista economico in tutte le sue componenti, nell'ottica anche di un ipotetico deployment su larga scala.
\end{enumerate}

\iffalse
In questa sezione esporre brevemente i requisiti a cui il sistema proposto deve rispondere, concentrando l'attenzione sugli aspetti più rilevanti e facendo eventualmente uso di opportuni diagrammi di alto livello.\\

Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 4000 & 6000 \\
 2 componenti & 6000 & 8000 \\
 3 componenti & 8000 & 10000 \\
 \hline
\end{tabular}
\fi


\newpage


%----------------------------------------------------------------------------------------
%	PROGETTAZIONE
%----------------------------------------------------------------------------------------

\section{Progettazione}

In questa sezione sono esposte le scelte progettuali operate nelle varie fasi di sviluppo dell'elaborato.

\subsection{Metodologia}

La metodologia alla base del progetto si compone di tre parti fondamentali: (1) rilevamento del volto (\textit{face detection}), (2) rilevamento dei punti di riferimento facciali (\textit{facial landmark detection}) e (3) rilevamento della sonnolenza. Ciascuno di questi problemi può essere affrontato con diversi approcci risolutori noti in letteratura. Dal momento che ogni tecnica possiede sia aspetti positivi che negativi, la scelta di quale adottare per il problema di riferimento deve essere frutto di un'attenta analisi in funzione dei requisiti che si devono soddisfare (già evidenziati nella sezione \ref{sec:requisiti}). La valutazione e lo studio delle soluzioni che possono essere intraprese nelle fasi metodologiche costituiscono pertanto due elementi chiave per una valida progettazione. Esse assumono inoltre un ruolo preponderante nella determinazione del successo o del fallimento degli obiettivi stabiliti dall'elaborato stesso. Nei successivi paragrafi si discutono in maggior dettaglio le problematiche emerse sul piano progettuale e si giustificano le scelte intraprese.

\subsubsection{Rilevamento del volto}

Rilevare la presenza del volto del conducente e localizzarne la posizione all'interno di un'immagine rappresenta un'operazione centrale in tutti i progetti di \textit{drowsiness detection} basati su misure comportamentali e, quindi, algoritmi principalmente connessi alla Computer Vision. I localizzatori allo stato dell'arte più utilizzati in letteratura sono di seguito riportati, classificandoli nelle due principali famiglie con cui possono essere distinti.
\begin{itemize}
	\item \textbf{Tecniche feature-based}. Usano esplicitamente la conoscenza dell'aspetto del volto, caratterizzato da un insieme di feature di basso livello: proprietà dei pixel, informazioni sulla geometria del volto e modelli standard definiti manualmente o descritti da funzioni (\textit{template matching}).
	\item \textbf{Tecniche image-based}. Affrontano il problema della localizzazione del volto come un generico problema di pattern recognition dove l'obiettivo è imparare a riconoscere l'immagine di un viso sulla base di alcuni esempi di training.
	\begin{itemize}
		\item \textbf{Haar Cascade Classifier.}\\
		È una tecnica di Machine Learning proposta da Paul Viola e Michael Jones nel 2001\cite{X}, introdotta per la localizzazione di oggetti e applicata poi con successo all'individuazione di volti. Il localizzatore di Viola e Jones, nello specifico, è uno dei più robusti ed efficienti allo stato dell'arte. La procedura d'individuazione del volto, infatti, consente un funzionamento real-time. Tuttavia l'addestramento è molto lento (può richiedere giorni) e necessita di numerose istanze sia di esempi positivi che negativi.
		Internamente utilizza un classificatore in grado di associare un pattern in input a una delle due classi volto e non volto. Ciò è possibile poichè le immagini contenenti volti hanno proprietà comuni, mentre quelle che non li rappresentano sono estremamente irregolari.
		\begin{itemize}
			\item \textbf{Haar-like feature.}\\
			La localizzazione dei volti avviene analizzando sottofinestre consecutive (sovrapposte e di dimensione variabile) dell'immagine in input, estraendo le feature presenti nella finestra e classificando la finestra stessa come volto o non volto. Le feature Haar-like sono caratterizzate dall'applicazione di regioni rettangolari di colorazione bianca e nera unite tra loro, come mostrato in Figura \ref{Y}. Ogni feature è posizionata in una sottoregione di una sottofinestra dell'immagine e il suo valore è calcolato come somma pesata di due componenti: la somma dei pixel nella regione nera e la somma di quelli interni alla ragione bianca. I segni dei due pesi sono opposti e i loro valori assoluti sono inversamente proporzionali alle aree delle rispettive regioni, in modo da effettuare un calcolo normalizzato. Le feature Haar-like, inoltre, sono applicate modificandone la dimensione, la forma e la posizione nella sottofinestra. Il motivo legato al loro uso è da ricercarsi nella loro efficacia ai fini della localizzazione del volto e nell'efficienza con cui possono essere calcolate mediante l'impiego dell'immagine integrale. Nonostante la rapidità con cui è possibile individuarle, occorre osservare come a ogni sottofinestra possano nella pratica corrispondere diverse miliaia di feature associate.
			\item \textbf{Immagine integrale.}\\
			Le semplici feature rettangolari di un'immagine sono calcolate utilizzando una rappresentazione intermedia dell'immagine stessa, chiamata immagine integrale. L'immagine integrale in posizione (x,y) corrisponde alla somma del valore dei pixel sopra e a sinistra di (x,y).
			\item \textbf{AdaBoost.}\\
			AdaBoost è una tecnica di addestramento che ha l'obiettivo di costruire un classificatore non lineare complesso e robusto come combinazione lineare di M classificatori più semplici detti classificatori deboli, apprendendo la loro sequenza ottimale e i corrispondenti pesi in modo da minimizzare l'upper bound all'errore di classificazione.
			\item \textbf{Classificatore a cascata.}\\
			Un solo classificatore robusto, per quanto elimini una grande porzione di sottofinestre che non contengono volti (grazie alla sua caratteristica di essere non lineare), non soddisfa i requisiti di applicazioni in termini d'efficienza e di percentuale ridotta di falsi allarmi. Una possibile soluzione consiste nell'impiego di classificatori robusti in cascata, a complessità crescente. Ogni stage del classificatore a cascata mostra la regione definita dalla locazione corrente della finestra scorrevole come positiva (se il volto è stato trovato) o negativa (se il volto non è stato trovato). Se l'etichetta è negativa, la classificazione di quella regione è completa e la finestra scorrevole viene spostata sulla locazione successiva. Se invece l'etichetta è positiva, il classificatore passa la regione allo stage successivo. L'intero classificatore a cascata riporta il volto come individuato nella locazione della finestra scorrevole solo se l'ultimo stage giunge a classificare la regione come positiva. Tale approccio è usato per eliminare velocemente regioni meno probabili in modo da non richiedere elaborazione ulteriore quando non necessario.
		\end{itemize}
		\item \textbf{LBP Cascade Classifier.}\\
		LBP\footnote{LBP. Local Binary Patterns.} è un classificatore che, come Haar, necessita di essere addestrato con centinaia di immagini. Ogni immagine di training è divisa in blocchi e per ogni blocco LBP adotta una finestra di 9 pixel (3x3), osservando con un particolare interesse il pixel collocato centralmente. Successivamente l'algoritmo compara il valore del pixel centrale con quello di ogni vicino all'interno della finestra 3x3. Ciascun pixel vicino con valore maggiore o uguale a quello del pixel centrale viene posto a 1, mentre i rimanenti a 0. Successivamente, i valori dei pixel aggiornati vengono letti in ordine orario, formando un numero binario. Tale numero binario viene poi convertito in notazione decimale e assegnato come nuovo valore del pixel centrale. L'operazione viene poi ripetuta per ogni pixel nel blocco. Infine, ogni valore contenuto in un blocco viene convertito in un istogramma. Concatenando gli istogrammi di ogni blocco si giunge a formare il vettore di feature per l'immagine.
		\item \textbf{HOG.}
	\end{itemize}
\end{itemize}

\subsubsection{Rilevamento dei punti di riferimento facciali}

\subsubsection{Rilevamento della sonnolenza}

\subsection{Architettura software}

\subsubsection{Flowchart dell'algoritmo}

\subsection{Architettura fisica}

\iffalse

- flowchart
- face detection
	- Viola-Jones
	- LBP
	- HOG
	- perchè non Deep Learning / CNN e LGBP
	- input del modello per il rilevamento del volto
- facial landmark detection
- EAR
	- perchè non PERCLOS
	- perchè non template matching
	- importanza blink detection
	- eye blinking (tempi e osservazioni)
	- EAR threshold
	- EAR SVM
	- EAR con HMM
	- perchè usare EAR con threshold
	- numero di frame consecutivi
- circuito fritzing

Devono essere esposte le scelte progettuali operate nelle varie fasi di sviluppo dell'elaborato.\\

In questa sezione devono essere documentati gli schemi di progetto relativamente all'architettura complessiva del sistema e alle sue componenti di rilievo che possano meritare un'analisi di dettaglio. Per le componenti software si può ricorrere ad esempio a diagrammi delle classi, di sequenza, stato, attività. Per le componenti hardware è possibile includere opportuni schemi in grado di descrivere l'architettura fisica adottata.\\

Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 9000 & 18000 \\
 2 componenti & 12000 & 21000 \\
 3 componenti & 15000 & 24000 \\
 \hline
\end{tabular}
\fi

\newpage


%----------------------------------------------------------------------------------------
%	IMPLEMENTAZIONE
%----------------------------------------------------------------------------------------

\section{Implementazione}\label{sec:implementazione}

In questa sezione vengono dimostrate le fasi di configurazione del dispositivo, la realizzazione del circuito elettronico e la scrittura degli script per l'analisi dei video e dei dati ottenuti.

\subsection{Configurazione Dispositivo}
Prima di essere utilizzato, il Raspberry PI dev'essere opportunamente configurato: non è sufficiente, infatti, alimentarlo o ottenere soltanto un IDE dedicato; esso necessita di un vero e proprio sistema operativo sul quale far affidamento. Solo successivamente, interagendo direttamente con esso, si potranno svolgere tutte le operazioni di progettazione, sviluppo e testing.

\subsubsection{Memoria (MicroSD)}
Tutto il software necessario per il corretto funzionamento del Raspberry dev'essere caricato in una scheda MicroSD, opportunamente tarata per uno specifico progetto in termini di capacità disponibile. La scheda risulta essere facilmente reperibile ad un prezzo contenuto su qualsiasi negozio fisico o virtuale avente a che fare con il mondo di elettronica: per questo motivo si preferisce di lasciare un modesto margine di memoria libera e di ricadere su una capacità di 32GB, ampiamente sufficiente per contenere il sistema operativo, vari IDE per lo sviluppo e l'intero dataset. Il procedimento di configurazione può essere suddiviso in due parti: la prima, tramite un Personal Computer di appoggio e la seconda, direttamente sul dispositivo inizializzato.

\subsubsection{Installazione Sistema Operativo}
In questa fase la MicroSD dev'essere connessa al Personal Computer che verrà utilizzato per configurarla: infatti, prima di essere utilizzata direttamente sul Raspberry, la MicroSD dev'essere opportunamente formattata in formato FAT32; per eseguire questa operazione si fa riferimento al software \quotes{SD Memory Card Formatter} (disponibile per Windows e Mac), che in pochi passaggi e poco tempo esegue l'operazione richiesta. Successivamente si provvede alla scelta del Sistema Operativo che il Raspberry metterà in esecuzione. Questa scelta ricade sull'utente e sugli eventuali vincoli da soddisfare: esistono infatti innumerevoli distro Linux disponibili gratuitamente al download e pronte all'utilizzo. Seguendo le linee guida riportate direttamente sul sito del produttore del Raspberry, si sceglie la distribuzione \textbf{Raspbian}: essa risulta essere basata su Debian, opportunamente ottimizzato per funzionare sul Raspberry. Il caricamento di quest'ultimo può avvenire in due modi: attraverso l'operazione di \quotes{flash} del sistema operativo direttamente sulla MicroSD, oppure tramite un installer (chiamato NOOBS, \textit{New Out Of the Box Software}). Per facilità di installazione, si preferisce la seconda: dopo l'ottenimento dell'archivio \textit{.zip} dal sito ufficiale, si estrae il suo contenuto direttamente dentro la MicroSD formattata in precedenza. Così facendo, il dispositivo potrà avviare una modalità d'installazione, nella quale scegliere, successivamente, tutti i componenti aggiuntivi da installare al sistema operativo. Soltanto adesso la MicroSD può essere rimossa dal computer e inserita dentro il Raspberry nell'apposito slot.\\

Per procedere nei successivi passi di configurazione si ha necessità di alcune periferiche input/output connesse direttamente al Raspberry: una tastiera, un mouse e un monitor con entrata HDMI, nonchè un cavo HDMI per collegare il device al monitor e l'alimentatore per il Raspberry (5V, 2.1A). Si collega l'alimentatore nell'apposito ingresso MicroUSB, facendo partire l'installazione guidata. Tramite mouse e tastiera si selezionano le preferenze riguardanti il software da installare, che in questo caso risulta essere soltanto il sistema operativo completo di alcuni tool e programmi preinstallati. Completata la procedura d'installazione, il device è pronto all'utilizzo e si può procedere alla seconda fase di configurazione.

\subsubsection{Installazione Software e Librerie}
Il computer utilizzato nella prima fase della configurazione può essere ora spento, dato che il Raspberry risulta essere ora, a tutti gli effetti, un completo computer con un browser, accesso a internet (previa connessione via WiFi o Ethernet) e diversi software per lo sviluppo. Gli strumenti forniti di default non sono comunque sufficienti ai fini del progetto, per cui si procede alla manuale configurazione e installazione dei vari software / pacchetti / librerie / tool per permettere e facilitare il successivo sviluppo. Gli strumenti illustrati successivamente devono essere necessariamente installati nell'ordine in cui appaiono, altrimenti vi è il rischio che non ci siano dipendenze sufficienti.\\

Prima di procedere con qualsiasi modifica, è buona norma assicurarsi che il pacchetto per l'ottenimento del software aggiuntivo sia aggiornato. Si eseguono due comandi per effettuare la verifica:
\begin{lstlisting}
sudo apt-get update
sudo apt-get upgrade
\end{lstlisting}


L'unico software aggiunto al sistema operativo è \textbf{Visual Studio Code}: il programma si presenta come un editor testuale, con supporto a diversi linguaggi e script; abilita l'highlight del codice e un discreto aiuto con suggerimenti durante la fase di immissione testo, per quanto riguarda nomi variabili, metodi ecc... Verrà installato sotto il nome di "inserire il nome qui" e si ottiene utilizzando la console, tramite due comandi:

\begin{lstlisting}
wget https://packagecloud.io/headmelted/codebuilds/gpgkey 
-O - | sudo apt-key add -
\end{lstlisting}

\begin{lstlisting}
curl -L https://code.headmelted.com/installers/apt.sh
| sudo bash
\end{lstlisting}

Successivamente si procede all'installazione della libreria \textbf{OpenCV}, discussa nel capitolo "inserire il capitolo qui". Per funzionare correttamente e in modo ottimizzato sul Raspberry esiste una versione ad hoc, pensata per i dispositivi con poca capacità di calcolo. Per poterla eseguire è necessario però installare alcune dipendenze, quali \textit{libhdf5-dev}, \textit{libhdf5-serial-dev}, \textit{libqtwebkit4} e \textit{libqt4-test}, il package manager di Python e il gestore degli ambienti virtuali di Python. Le \textbf{dipendenze} sono facilmente ottenibili tramite l'esecuzione di pochi comandi:
	
\begin{lstlisting}
sudo apt-get install libhdf5-dev libhdf5-serial-dev
sudo apt-get install libqtwebkit4 libqt4-test
\end{lstlisting}

Lo stesso discorso vale per il Package Manager di Python \textbf{(PIP)}. Esso si ottiene mediante i comandi:

\begin{lstlisting}
wget https://bootstrap.pypa.io/get-pip.py
sudo python3 get-pip.py
\end{lstlisting}
			
Per poter lavorare comodamente con diversi progetti che richiedono diverse librerie, è preferibile utilizzare ambienti virtuali. Essi sono facilmente intercambiabili e permettono di evitare conflitti di librerie nel caso in cui si vuole gestire più progetti Python in un unico device. Utilizzando \textit{PIP} si può facilmente ottenere il \textbf{Gestore degli Ambienti Virtuali}:
\begin{lstlisting}
pip install virtualenv virtualenvwrapper
\end{lstlisting}	
			
Per utilizzare i comandi resi disponibili dal precedente pacchetto, occorre modificare il file \textit{~/.profile}: si può utilizzare un editor di testo a piacere (vim, nano o qualsiasi tool grafico) per inserire alla fine di questo file le seguenti righe:

\begin{lstlisting}
# virtualenv and virtualenvwrapper
export WORKON_HOME=$HOME/.virtualenvs
export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3
source /usr/local/bin/virtualenvwrapper.sh
\end{lstlisting}

I comandi sono pronti ora all'utilizzo, ma ogni tal volta in cui si apre una nuova finestra console è necessario eseguire il seguente comando per far riconoscere come validi i comandi per la gestione degli ambienti virtuali:

\begin{lstlisting}
source ~/.profile
\end{lstlisting}

La creazione di un ambiente virtuale avviene a liena di comando. Per creare un nuovo ambiente virtuale di nome \quotes{cv} si esegue il seguente comando:
\begin{lstlisting}
mkvirtualenv cv -p python3
\end{lstlisting}

Successivamente, per impostarlo come attuale ambiente sul quale si sta lavorando, si esegue:
\begin{lstlisting}
workon cv
\end{lstlisting}

Soltanto ora è possibile installare ulteriori dipendenze senza che quest'ultime possano mai andare in conflitto tra diversi progetti eventualmente gestiti. Trovandosi ora in un ambiente virtuale chiuso, tutte le librerie installate da ora in poi saranno visibili esclusivamente nell'ambiente chiamato \quotes{cv}. Si procede dunque all'installazione di \textbf(OpenCV) per Python:
\begin{lstlisting}
pip install opencv-contrib-python
\end{lstlisting}

Ci sono diverse classi di appoggio sulle quali si possono effettuare operazioni di elaborazione di immagini. Si preferisce l'utilizzo della libreria \textit{imutils}, ricca di funzionalità e di facile utilizzo. La procedura d'installazione è la classica e prevede l'esecuzione del comando:
\begin{lstlisting}
pip install imutils
\end{lstlisting}

Infine, per poter utilizzare la RaspiCam direttamente in Python si utilizzerà una libreria di appoggio, installata tramite il seguente comando:
\begin{lstlisting}
pip install "picamera[array]"
\end{lstlisting}

Prima di procedere al vero e proprio sviluppo del progetto, viene consigliato di testare le librerie appena installate. Senza chiudere la finestra precedentemente aperta (oppure aprendone una nuova e rieseguendo i comandi per il cambio dell'ambiente virtuale)  si possono eseguire in ordine i comandi:
\begin{python}
python
import cv2
import imutils
\end{python}

Se tutto funziona correttamente e non vengono restituiti errori di nessun genere, si può procedere allo sviluppo e utilizzo completo delle librerie. Nel caso in cui i comandi di sopra producessero errori, si può procedere all'integrazione di alcune librerie probabilmente mancanti oppure provare a reinstallarle tutte dall'inizio su un nuovo ambiente virtuale, facendo molta attenzione all'ordine e all'effettivo completamento dell'installazione dei singoli pacchetti senza alcun genere di errore in output. Le eventuali librerie da aggiungere, nel caso di problemi, devono essere installati fuori dall'ambiente virtuale: è sufficiente aprire una nuova finestra di console ed eseguire uno ad uno i seguenti comandi:
\begin{lstlisting}
sudo apt-get install libatlas-base-dev
sudo apt-get install libjasper-dev
sudo apt-get install libqtgui4
sudo apt-get install python3-pyqt5
\end{lstlisting}



%- OpenCV
%- Python
%- Dlib
%- Imutils
%- Fissaggio camera
%- Script

%Esporre i principali problemi affrontati durante l'effettiva realizzazione delle componenti hardware/software e illustrare le soluzioni implementative adottate. Se l'elaborato ha previsto l'utilizzo di tecnologie già disponibili sul mercato, discuterne brevemente le caratteristiche e motivarne l'adozione rispetto ad altre soluzioni assimilabili.\\

%\textbf{NOTA: in questa sezione devono essere riportate esclusivamente le porzioni di codice ritenute particolarmente significative. Il codice sorgente nella sua interezza, opportunamente commentato, deve essere consegnato separatamente dalla relazione in un archivio compresso.}\\


%Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

%\vspace{1cm}
%\begin{tabular}{l|rr}
% & Numero minimo di battute & Numero massimo di battute \\
% \hline
% 1 componente & 5000 & 11000 \\
% 2 componenti & 8000 & 16000 \\
% 3 componenti & 10000 & 21000 \\
% \hline
%\end{tabular}


\newpage


%----------------------------------------------------------------------------------------
%	TESTING E PERFORMANCE
%----------------------------------------------------------------------------------------

\section{Testing e performance}

\begin{table}[h]
	\centering
	\begin{tabular}{cc|c|c|}
		\cline{3-4}
		&        & \multicolumn{2}{c|}{Predicted} \\ \cline{3-4} 
		&        & Alert         & Drowsy         \\ \hline
		\multicolumn{1}{|c|}{\multirow{2}{*}{Given}} & Alert  & TN & FP\\ \cline{2-4} 
		\multicolumn{1}{|c|}{}                       & Drowsy & FN & TP\\ \hline
	\end{tabular}
	\caption{Matrice di confusione con $EAR_{th}=0.3$}
	\label{table:cm_0_3}
\end{table}

\begin{landscape}
\begin{table}[]
	\centering
	\begin{adjustbox}{width=1.4\textwidth}
	\begin{tabular}{lllllllllllllccllll}
		& & & & & & & & & & & & & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & & & &\\ \cline{5-19}
		& & & \multicolumn{1}{l|}{} & \multicolumn{4}{c|}{Confusion Matrix} & \multicolumn{5}{c|}{Category Statistical Indices} & \multicolumn{3}{c|}{Daytime Statistical Indices} & \multicolumn{3}{c|}{Global Statistical Indices}\\ \hline
		\multicolumn{4}{|c|}{Category} & \multicolumn{1}{l|}{TP} & \multicolumn{1}{l|}{TN} & \multicolumn{1}{l|}{FP} & \multicolumn{1}{l|}{FN} & \multicolumn{1}{l|}{Accuracy} & \multicolumn{1}{l|}{Precision} & \multicolumn{1}{l|}{MR} & \multicolumn{1}{l|}{TPR} & \multicolumn{1}{l|}{FPR} & \multicolumn{1}{c|}{Accuracy} & \multicolumn{1}{c|}{TPR} & \multicolumn{1}{l|}{FPR} & \multicolumn{1}{l|}{Accuracy} & \multicolumn{1}{l|}{TPR} & \multicolumn{1}{l|}{FPR}\\ \hline
		\multicolumn{1}{|l|}{\multirow{8}{*}{Day}} & \multicolumn{1}{l|}{\multirow{4}{*}{Drowsiness}} & \multicolumn{1}{l|}{\multirow{2}{*}{Glasses}} & \multicolumn{1}{l|}{Static} & \multicolumn{1}{l|}{372} & \multicolumn{1}{l|}{2005} & \multicolumn{1}{l|}{501} & \multicolumn{1}{l|}{702} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{\multirow{8}{*}{}} & \multicolumn{1}{c|}{\multirow{8}{*}{}} & \multicolumn{1}{l|}{\multirow{8}{*}{}} & \multicolumn{1}{l|}{\multirow{16}{*}{}} & \multicolumn{1}{l|}{\multirow{16}{*}{}} & \multicolumn{1}{l|}{\multirow{16}{*}{}}\\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{163} & \multicolumn{1}{l|}{1870} & \multicolumn{1}{l|}{78} & \multicolumn{1}{l|}{574} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}\\ \cline{3-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\multirow{2}{*}{NoGlasses}} & \multicolumn{1}{l|}{Static}  & \multicolumn{1}{l|}{1409} & \multicolumn{1}{l|}{3141} & \multicolumn{1}{l|}{357} & \multicolumn{1}{l|}{463} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}\\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{991} & \multicolumn{1}{l|}{2319} & \multicolumn{1}{l|}{43} & \multicolumn{1}{l|}{227} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{2-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{\multirow{4}{*}{NoDrowsiness}} & \multicolumn{1}{l|}{\multirow{2}{*}{Glasses}} & \multicolumn{1}{l|}{Static} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{2390} & \multicolumn{1}{l|}{295} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}\\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1749} & \multicolumn{1}{l|}{41} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}\\ \cline{3-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\multirow{2}{*}{NoGlasses}} & \multicolumn{1}{l|}{Static} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{2633} & \multicolumn{1}{l|}{52} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{2590} & \multicolumn{1}{l|}{95} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}\\ \cline{1-16}
		\multicolumn{1}{|l|}{\multirow{8}{*}{Night}} & \multicolumn{1}{l|}{\multirow{4}{*}{Drowsiness}} & \multicolumn{1}{l|}{\multirow{2}{*}{Glasses}} & \multicolumn{1}{l|}{Static} & \multicolumn{1}{l|}{327} & \multicolumn{1}{l|}{1015} & \multicolumn{1}{l|}{186} & \multicolumn{1}{l|}{262} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{\multirow{8}{*}{}} & \multicolumn{1}{c|}{\multirow{8}{*}{}} & \multicolumn{1}{l|}{\multirow{8}{*}{}} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{103} & \multicolumn{1}{l|}{392} & \multicolumn{1}{l|}{978} & \multicolumn{1}{l|}{317} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}\\ \cline{3-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\multirow{2}{*}{NoGlasses}} & \multicolumn{1}{l|}{Static} & \multicolumn{1}{l|}{259} & \multicolumn{1}{l|}{1376} & \multicolumn{1}{l|}{160} & \multicolumn{1}{l|}{890} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{314} & \multicolumn{1}{l|}{1447} & \multicolumn{1}{l|}{294} & \multicolumn{1}{l|}{630} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{2-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{\multirow{4}{*}{NoDrowsiness}} & \multicolumn{1}{l|}{\multirow{2}{*}{Glasses}} & \multicolumn{1}{l|}{Static} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1330} & \multicolumn{1}{l|}{460} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{655} & \multicolumn{1}{l|}{1135} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{3-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\multirow{2}{*}{NoGlasses}} & \multicolumn{1}{l|}{Static}  & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1542} & \multicolumn{1}{l|}{248} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \cline{4-13}
		\multicolumn{1}{|l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dynamic} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1207} & \multicolumn{1}{l|}{583} & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} \\ \hline
		& & & & & & & & & & & & & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & & & &
	\end{tabular}
	\end{adjustbox}
\caption{Accuratezza del rilevatore di sonnolenza con $EAR_{th}=0.3$}
\label{table:test}
\end{table}
\end{landscape}

\begin{equation}
Accuracy = \frac{TP + TN}{TP + TN + FP + FN} \times 100
\end{equation}

\begin{equation}
Precision = \frac{TP}{TP + FP} \times 100
\end{equation}

\begin{equation}
MisclassificationRate = \frac{FP + FN}{TP + TN + FP + FN} \times 100
\end{equation}

\begin{equation}
TPR = \frac{TP}{TP + FN} \times 100
\end{equation}

\begin{equation}
FPR = \frac{TN}{TN + FP} \times 100
\end{equation}

\begin{center}
	\framebox{\begin{tikzpicture}
		\begin{loglogaxis}[title={\textbf{ROC Curve}}, xlabel=Rate of False Positive (\%), ylabel=Rate of True Positive (\%), scale=1.5]
		\addplot plot coordinates {
			(0, 8.312e-02)
			(10, 2.547e-02)
			(20, 7.407e-03)
			(30, 2.102e-03)
			(40, 5.874e-04)
			(50, 1.623e-04)
			(60, 4.442e-05)
			(70, 1.207e-05)
			(80, 3.261e-06) };
		\legend{DrowsinessDetector\\}
		\end{loglogaxis}
	\end{tikzpicture}}
\end{center}

\iffalse
- orientamento testa
- distanza minima e massima di funzionamento

Esporre lo stato di funzionamento effettivo del sistema progettato ad elaborato concluso. Per ciascuna delle funzionalità salienti devono essere tabellate e discusse le performance riscontrate mediante opportuni test eseguiti in fase di validazione del progetto.\\

I tempi di esecuzione/comunicazione devono essere accompagnati dalle caratteristiche dell'hardware sul quale è eseguito il software.\\

Qualora l'elaborato includa algoritmi innovativi, indicarne la complessità computazionale (avendo cura di esporre lo pseudo codice nella sezione \ref{sec:implementazione}).\\


Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 2000 & 3000 \\
 2 componenti & 2500 & 4500 \\
 3 componenti & 3000 & 6000 \\
 \hline
\end{tabular}
\fi

\newpage


%----------------------------------------------------------------------------------------
%	ANALISI DI DEPLOYMENT SU LARGA SCALA
%----------------------------------------------------------------------------------------

\section{Analisi di deployment su larga scala}

In questa sezione va discussa, eventualmente con l'ausilio di opportuni diagrammi (componenti, deployment), l'evoluzione del progetto presentato immaginando che venga adottato su larga scala. I dettagli qui esposti devono quindi astrarre dalle specifiche dell'elaborato qualora l'implementazione sia stata focalizzata su uno scenario isolato.\\

A titolo d’esempio, qualora applicabile, devono essere evidenziate le criticità che si potrebbero incontrare e devono essere proposte soluzioni tipiche in contesti di \textit{cloud architecture} per garantire un'adeguata \textit{resilienza}, in termini di \textit{availability} e \textit{scalability} del sistema.\\


Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 3000 & 6000 \\
 2 componenti & 4500 & 9000 \\
 3 componenti & 6000 & 12000 \\
 \hline
\end{tabular}


\newpage


%----------------------------------------------------------------------------------------
%	PIANO DI LAVORO
%----------------------------------------------------------------------------------------

\section{Piano di lavoro}

In questa sezione devono essere chiariti i compiti svolti da ciascun candidato nel caso in cui il gruppo abbia più di un componente.\\

Deve essere inoltre esposto il piano di lavoro adottato. A tal fine, per ogni attività svolta durante la preparazione dell'elaborato (ad esempio: studio di una tecnologia, progettazione di un componente, implementazione di un algoritmo ecc…) deve essere chiarita la collocazione temporale e devono essere indicate le risorse impiegate per svolgerla (giorni/uomo). I candidati possono ricorrere a opportuni diagrammi come quello di Gantt.\\


Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 1000 & 2000 \\
 2 componenti & 1500 & 3000 \\
 3 componenti & 2000 & 4000 \\
 \hline
\end{tabular}

\newpage


%----------------------------------------------------------------------------------------
%	CONCLUSIONI
%----------------------------------------------------------------------------------------

\section{Conclusioni}

However, it has been found that the rate of detecting the correct feature, or the percentage of success among a number of detection attempts, varies depending on the application and number of classes. The determination of drowsiness using PERCLOS and Eye Blink has a success rate of close to 100\% [43] and 98\% [45], respectively. However it has to be noted that, the high positive detection rate achieved by [43] was when the subjects didn’t wear glasses. Likewise, as most researchers conducted their experiments in simulated environment they achieved a higher success rate. The positive detection rate decreased significantly when the experiment was carried out in a real environment [15].
Another limitation of behavioral measure was brought out in an experiment conducted by Golz et al. They evaluated various drowsiness monitoring commercial products, and observed that driver state cannot be correlated to driving performance and vehicle status based on behavioral measures alone [57].

Esporre brevemente le considerazioni conclusive sul progetto presentato, indicando anche i possibili sviluppi futuri.\\

Vincoli circa la lunghezza della sezione (escluse didascalie, tabelle, testo nelle immagini, schemi):

\vspace{1cm}
\begin{tabular}{l|rr}
 & Numero minimo di battute & Numero massimo di battute \\
 \hline
 1 componente & 500 & 1000 \\
 2 componenti & 1000 & 2000 \\
 3 componenti & 1500 & 3000 \\
 \hline
\end{tabular}

\newpage


%----------------------------------------------------------------------------------------
%	APPENDICE
%----------------------------------------------------------------------------------------

\appendix
\addcontentsline{toc}{section}{Appendice}
\section*{Appendice}
Laddove necessario è possibile avvalersi di appendici alla relazione per includere materiale di approfondimento.\\

A titolo esemplificativo possono essere incluse le schede tecniche dei componenti adottati, la normativa di riferimento che regola un particolare dominio applicativo, ecc.


\newpage


%----------------------------------------------------------------------------------------
%	RIFERIMENTI BIBLIOGRAFICI
%----------------------------------------------------------------------------------------

\bibliography{relazione}
\bibliographystyle{unsrt}

%----------------------------------------------------------------------------------------

\end{document}